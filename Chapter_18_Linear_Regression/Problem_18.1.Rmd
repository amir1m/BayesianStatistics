---
title: "18.1 Crime and punishment"
output: html_notebook
---


The data in linearRegression_crimePunishment.csv contains the murder rate per capita and the rate of automobile crimes per 100,000 individuals (both on the log scale) in the ten US States that have changed their legislation on capital punishment since 1960 (in all cases the states abolished capital punishment). We also include a dummy variable (“law”) that is 1 if the state allows capital punishment in that year, and 0 otherwise. The crime data is from http://www.disastercenter.com.

# Problem 18.1.1. 
Graph the data and comment on any trends.

```{r}
crime_data <- read.csv('linearRegression_crimePunishment.csv')
crime_data
```

```{r}
library(tidyverse)

```



```{r}
ggplot(data=filter(crime_data, stateName=='Connecticut'), aes(year)) + geom_line(aes(y=murder, color="murder")) + geom_line(aes(y=car/2, color="car")) + geom_line(aes(y=law, color='law'))

```



```{r}
df <- filter(crime_data, stateName=='Connecticut') %>%
  select(year, murder, car, law) %>%
  gather(key="variable", value = "value", -year)

ggplot(df, aes(x=year, y=value)) +
  geom_line(aes(color=variable, linetype=variable)) + ggtitle("Connecticut") + theme(plot.title = element_text(hjust = 0.5)) 


```

```{r}


for (lstate in unique(crime_data$stateName)){
  df <- filter(crime_data, crime_data$stateName == lstate) %>%
  select(year, murder, car, law) %>%
  gather(key="variable", value = "value", -year)
  
  print(ggplot(df, aes(x=year, y=value)) +
  geom_line(aes(color=variable, linetype=variable)) +  ggtitle(lstate) + theme(plot.title = element_text(hjust = 0.5)))
  
}

```

# Problem 18.1.2. 
A simple model for murder rates is of the form,

            murderi,t ∼ N (α + βpenaltyi,t + γcari,t, σ) (18.1)

where we assume that the effect of having the death penalty is given by β, which is assumed to be the same across all states. We include cari,t – a measure of crimes on automobiles, as an independent variable to proxy for the contemporaneous underlying level of crime. Estimate this model and hence determine whether the death penalty acts as a deterrent to murder.

```{r}
library(rstan)
options(mc.cores = parallel::detectCores())
```


```{r}
dataList <- list(N = 540, murder = crime_data$murder, car = crime_data$car,
                 law = crime_data$law, state = crime_data$state)
```


```{r}
fit <- stan(file = 'Model_Problem_18_1.stan', data = dataList, iter=1000, chains=4, seed=42)

```

```{r}
print(fit)
```
_Where we see that we estimate that the imposition of the death penalty on average raises the murder rate by on average 24%!_

# Problem 18.1.3. 
An alternative model allows there to be state-level effects,

        murderi,t ∼ N (αi + βipenaltyi,t + γicari,t, σi) , (18.2)

where we assume that αi ∼ N(α ̄,σα), βi ∼ N(β ̄,σβ) and γi ∼ N(γ ̄,σγ) (we assume fully heteroge- neous estimates for σ). Estimate the above model and compare the results with the homogeneous
coefficient model.
```{r}
K = length(unique(crime_data$stateName))
K
```


```{r}
dataList <- list(N = 540, K = length(unique(crime_data$stateName)), murder = crime_data$murder, car = crime_data$car, law = crime_data$law, state = crime_data$state)
```

```{r}
fit_hetrogenous <- stan(file = 'Model_Hetrogeneous_Prob_18_1.stan', data = dataList, iter=1000, chains=4, seed=42)
```

```{r}
print(fit_hetrogenous)
```
With a mean effect size of a 26% reduction in murder rates although with a much wider range of effects.

# Problem extra. (Not in main text but wanted to include) 
Another model allows there to be time trends in the data,
    murderi,t ∼ N (αi + δit + βipenaltyi,t + γicari,t, σi) , (18.3) where δi ∼ N(δ ̄,σδ). 

Again estimate this model and compare the effect size of the death penalty across the three models.

```{r}
fit_time_trends <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, seed=42)
```

```{r}
print(fit_time_trends)
```
## Fixing divergent iterations
Let's try by increasing control = list(adapt_delta = 0.9)

```{r}
fit_time_trends_2 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.9), seed=42)
```
```{r}
print(fit_time_trends_2)
```
Lets try now further increasing step size from 0.9 to 0.95

```{r}
fit_time_trends_3 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.95), seed=42)
```

Still 5 divergent transitions after warmup.Lets increase iterations as well?

```{r}
fit_time_trends_4 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=2000, chains=4, control = list(adapt_delta = 0.95), seed=42)
```
Increasing no. of iteration didn't help! Incresed the divergent iterations to 23 from 5!

Lets go back to 1000 iterations

```{r}
fit_time_trends_5 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.95), seed=42)
```

```{r}
print(fit_time_trends_5)
```

### Lets diagnose more by following https://betanalpha.github.io/assets/case_studies/rstan_workflow.html

Get https://raw.githubusercontent.com/betanalpha/knitr_case_studies/master/qr_regression/stan_utility.R

```{r}
source('stan_utility.R')
lsf.str()
```


```{r}
check_n_eff(fit_time_trends_5)
```

```{r}
check_rhat(fit_time_trends_5)
```

```{r}
check_treedepth(fit_time_trends_5)
```

```{r}
check_div(fit_time_trends_5)
```

Let's increase adapt delta to 0.98
```{r}
fit_time_trends_6 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.98), seed=42)
```
### Fixing Maximum Treedepth

```{r}
check_treedepth(fit_time_trends_6)
```

Lets try using tredepth to 15 as : control=list(max_treedepth=15)

```{r}
fit_time_trends_6 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.98, max_treedepth=15), seed=42)
```
```{r}
fit_time_trends_7 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.99, max_treedepth=15), seed=42)
```

```{r}
fit_time_trends_7 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.995, max_treedepth=15), seed=42)
```


```{r}
fit_time_trends_8 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.995), seed=42)
```

```{r}
fit_time_trends_9 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.995,max_treedepth=13), seed=42)
```

```{r}
fit_time_trends_10 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.995,max_treedepth=20), seed=42)
```

```{r}
 fit_time_trends_10 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.998,max_treedepth=20), seed=42)
```

```{r}
fit_time_trends_11 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.998), seed=42)
```

```{r}
fit_time_trends_11 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1000, chains=4, control = list(adapt_delta = 0.998,max_treedepth=15 ), seed=42)
```


```{r}
fit_time_trends_12 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=2000, chains=4, control = list(adapt_delta = 0.998,max_treedepth=15 ), seed=42)
```

```{r}
fit_time_trends_12 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=1500, chains=4, control = list(adapt_delta = 0.998,max_treedepth=15 ), seed=42)
```

```{r}
fit_time_trends_12 <- stan(file = 'Model_timeTrends_Prob_18_1.stan', data = dataList, iter=3000, chains=4, control = list(adapt_delta = 0.998,max_treedepth=15 ), seed=42)
```

